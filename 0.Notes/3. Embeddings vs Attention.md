
## Example Sentence:
Let’s use the simple sentence:

```python
"I love AI"
```


We’ll walk through how embeddings and attention play different roles.



## Step 1: Embeddings — static context

Each token is mapped to a vector from an embedding matrix (pre-trained or learned):


### "I"     → [0.1, 0.3, 0.5]
### "love"  → [0.6, 0.2, 0.9]
### "AI"    → [0.8, 0.4, 0.7]


### What do embeddings do?

 - They encode global relationships across the language — like "king" and "queen" being close, or "cat" and "dog" being semantically similar.

 - But they're static: "I" always gets the same vector regardless of context.

**So embeddings tell us what a word means, not how it's used in this sentence.**


<br><br>


## Step 2: Attention — dynamic context

Now comes attention: the model asks, for each word,
    “which other words should I pay attention to when understanding this word?”

Let’s say we’re computing attention for the word "love":

We create Q, K, V vectors for each word, then compute dot-product attention.



### Hypothetical Attention Weights for "love":
| To     | Attention Weight |
| ------ | ---------------- |
| "I"    | 0.3              |
| "love" | 0.1              |
| "AI"   | 0.6              |

This tells us:

 - When processing "love", the model should focus mostly on "AI", then "I", then a bit on "love" itself.



### What attention does:

It uses these weights to dynamically combine the V (value) vectors to produce a context-aware representation of "love".

Now, "love" is not just "love", it's:

 - "love in the context of I and AI".


| Feature               | Embeddings                  | Attention                              |
| --------------------- | --------------------------- | -------------------------------------- |
| Role                  | Static word meaning         | Dynamic sentence-specific focus        |
| Same across use?      | Yes (in vanilla embeddings) | No, depends on surrounding words       |
| Knows about sentence? | ❌ No                        | ✅ Yes                                  |
| Learns context?       | ❌ No                        | ✅ Yes — **per word**, **per sentence** |



## Final Analogy

Embeddings = “your fixed personality”

Attention = “how much someone listens to others in a conversation depending on the topic”

You might be "funny" (embedding), but whether that matters in a conversation depends on context — attention decides how important that trait is right now.
